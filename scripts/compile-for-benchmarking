#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# This is a version of `scripts/compile` that uses the same data to generate
# variants of the existing data into an entries.csv with more than
# 10 million rows.
#

from oplcsv import Csv
from usernames import get_username
import os
import sys


MEETID = 0


def nextmeetid():
    global MEETID
    x = MEETID
    MEETID = MEETID + 1
    return x


LIFTERID = 1  # Due to default seed of LIFTERIDMAP below.


def nextlifterid():
    global LIFTERID
    x = LIFTERID
    LIFTERID = LIFTERID + 1
    return x


# Global map of (Name => LifterID) mappings.
LIFTERIDMAP = {
    'Sean Stangl Alpha': 0
}


def get_lifterid(name):
    global LIFTERIDMAP
    try:
        return LIFTERIDMAP[name]
    except KeyError:
        lifterid = nextlifterid()
        LIFTERIDMAP[name] = lifterid
        return lifterid


# Fills in the Age column from the BirthYear column if possible.
# Inexact ages derived in this way are noted as '.5', for example '23.5',
# designating "either 23 or 24".
def age_from_birthyear(csv, date):
    if 'BirthYear' not in csv.fieldnames:
        return

    if 'Age' not in csv.fieldnames:
        csv.append_column('Age')

    birthyearidx = csv.index('BirthYear')
    ageidx = csv.index('Age')
    [year, month, day] = date.split('-')

    for row in csv.rows:
        if row[birthyearidx] and not row[ageidx]:
            lower_age = int(year) - int(row[birthyearidx]) - 1
            assert lower_age < 120
            assert lower_age > 3
            row[ageidx] = str(lower_age) + '.5'


# Appends to entriescsv and meetscsv, while assigning a MeetID mapping.
def addmeet(permutation_name, entriescsv, meetscsv, entriespath, meetpath):
    newentries = Csv(entriespath)
    newmeet = Csv(meetpath)

    # Remove some columns that are allowed as data but are ignored.
    newentries.remove_column_by_name("BirthYear")
    newentries.remove_column_by_name("Country")
    newentries.remove_column_by_name("School")
    newentries.remove_column_by_name("Team")
    newentries.remove_column_by_name("State")
    newentries.remove_column_by_name("InternationalName")
    newentries.remove_column_by_name("Country-State")
    newentries.remove_column_by_name("College/University")
    newentries.remove_column_by_name("Tested")

    # Add the MeetID.
    assert "MeetID" in entriescsv.fieldnames
    assert "MeetID" in meetscsv.fieldnames
    assert "MeetID" not in newentries.fieldnames
    assert "MeetID" not in newmeet.fieldnames

    meetid = str(nextmeetid())

    newentries.append_column('MeetID')
    idx = newentries.index('MeetID')
    for row in newentries.rows:
        row[idx] = meetid

    newmeet.append_column('MeetID')
    idx = newmeet.index('MeetID')
    for row in newmeet.rows:
        row[idx] = meetid

    # Derive the path (e.g., "uspa/0039").
    # Input looks like "meet-path/uspa/0039/meet.csv".
    assert "MeetPath" not in newmeet.fieldnames
    path = meetpath[meetpath.index(
        os.sep) + 1: meetpath.rindex(os.sep)].replace(os.sep, '/')
    path = path + '-' + permutation_name
    assert ',' not in path

    newmeet.append_column("MeetPath")
    idx = newmeet.index("MeetPath")
    for row in newmeet.rows:
        row[idx] = path

    newmeet.rows[0][newmeet.index('MeetName')] += ' ' + permutation_name

    # Add the LifterIDs.
    newentries.append_column('LifterID')
    idx = newentries.index('LifterID')
    nameidx = newentries.index('Name')
    for row in newentries.rows:
        row[nameidx] = row[nameidx] + ' ' + permutation_name
        row[idx] = str(get_lifterid(row[nameidx]))

    age_from_birthyear(newentries, newmeet.rows[0][newmeet.index('Date')])

    entriescsv.cat(newentries)
    meetscsv.cat(newmeet)


# Generates the lifters.csv from global state.
def build_lifterscsv(lifterdir, builddir):
    # The map of Name => LifterID has already been populated.
    global LIFTERIDMAP
    assert len(LIFTERIDMAP)

    # Order by LifterID.
    ordered = sorted(LIFTERIDMAP.items(), key=lambda x: x[1])

    # Make a map of (Name => Instagram).
    socialcsv = Csv(lifterdir + os.sep + 'social-instagram.csv')
    nameidx = socialcsv.index('Name')
    igidx = socialcsv.index('Instagram')
    socialmap = dict()
    for row in socialcsv.rows:
        socialmap[row[nameidx]] = row[igidx]
    socialcsv = None

    lifterscsv = Csv()
    lifterscsv.append_column('LifterID')
    lifterscsv.append_column('Name')
    lifterscsv.append_column('Username')
    lifterscsv.append_column('Instagram')

    for (name, lifterid) in ordered:
        instagram = ''
        if name in socialmap:
            instagram = socialmap[name]

        username = get_username(name)

        row = [str(lifterid), name, username, instagram]
        lifterscsv.rows.append(row)

    lifterscsvpath = builddir + os.sep + 'lifters.csv'
    with open(lifterscsvpath, 'w') as fd:
        lifterscsv.write(fd)


def main(builddir, meetdir, lifterdir):
    entriescsv = Csv()
    meetscsv = Csv()

    # Standardize the column order by hardcoding it here.
    # This is necessary for SQL import statements to work.
    # If this list is modified, also modify scripts/compile-sqlite.
    entriescsv.append_column('MeetID')
    entriescsv.append_column('LifterID')
    entriescsv.append_column('Name')
    entriescsv.append_column('Sex')
    entriescsv.append_column('Event')
    entriescsv.append_column('Equipment')
    entriescsv.append_column('Age')
    entriescsv.append_column('Division')
    entriescsv.append_column('BodyweightKg')
    entriescsv.append_column('WeightClassKg')
    entriescsv.append_column('Squat1Kg')
    entriescsv.append_column('Squat2Kg')
    entriescsv.append_column('Squat3Kg')
    entriescsv.append_column('Squat4Kg')
    entriescsv.append_column('BestSquatKg')
    entriescsv.append_column('Bench1Kg')
    entriescsv.append_column('Bench2Kg')
    entriescsv.append_column('Bench3Kg')
    entriescsv.append_column('Bench4Kg')
    entriescsv.append_column('BestBenchKg')
    entriescsv.append_column('Deadlift1Kg')
    entriescsv.append_column('Deadlift2Kg')
    entriescsv.append_column('Deadlift3Kg')
    entriescsv.append_column('Deadlift4Kg')
    entriescsv.append_column('BestDeadliftKg')
    entriescsv.append_column('TotalKg')
    entriescsv.append_column('Place')
    entriescsv.append_column('Wilks')
    entriescsv.append_column('McCulloch')
    initial_entriescsv_num_columns = len(entriescsv.fieldnames)

    meetscsv.append_column('MeetID')
    meetscsv.append_column('MeetPath')
    meetscsv.append_column('Federation')
    meetscsv.append_column('Date')
    meetscsv.append_column('MeetCountry')
    meetscsv.append_column('MeetState')
    meetscsv.append_column('MeetTown')
    meetscsv.append_column('MeetName')
    initial_meetscsv_num_columns = len(meetscsv.fieldnames)

    # Enough permutations to guarantee > 10_000_000 entries.
    permutations = ['Alpha', 'Beta', 'Gamma', 'Delta', 'Epsilon',
                    'Zeta', 'Eta', 'Theta', 'Iota', 'Kappa',
                    'Lambda', 'Mu', 'Nu', 'Xi', 'Omicron',
                    'Pi', 'Rho', 'Sigma', 'Tau', 'Upsilon',
                    'Phi', 'Chi', 'Psi', 'Omega']

    for permutation in permutations:
        for dirname, subdirs, files in os.walk(meetdir):
            # Modifying `subdirs` in-place will cause the next iteration
            # of the os.walk() generator to operate over the sorted list.
            subdirs.sort()

            if 'entries.csv' in files:
                assert 'meet.csv' in files
                entriespath = dirname + os.sep + 'entries.csv'
                meetpath = dirname + os.sep + 'meet.csv'
                addmeet(permutation, entriescsv,
                        meetscsv, entriespath, meetpath)
        print("Done with %s..." % permutation)

    entriescsv.remove_column_by_name("AgeClass")

    # Construct the lifters.csv.
    build_lifterscsv(lifterdir, builddir)

    oplcsvpath = builddir + os.sep + 'openpowerlifting.csv'
    meetscsvpath = builddir + os.sep + 'meets.csv'

    with open(oplcsvpath, 'w') as fd:
        entriescsv.write(fd)
    with open(meetscsvpath, 'w') as fd:
        meetscsv.write(fd)

    # If these asserts fail, then new columns have been added.
    # Check the written files: new columns are at the end.
    # Columns need to be explicitly added above to be in a known order,
    # and then scripts/compile-sqlite needs to be notified of the column type.
    assert len(entriescsv.fieldnames) == initial_entriescsv_num_columns
    assert len(meetscsv.fieldnames) == initial_meetscsv_num_columns


if __name__ == '__main__':
    if len(sys.argv) != 4:
        print(' Usage: %s builddir meetdir lifterdir' %
              sys.argv[0], file=sys.stderr)
        sys.exit(1)
    main(sys.argv[1], sys.argv[2], sys.argv[3])
