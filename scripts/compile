#!/usr/bin/env python3
# vim: set ts=4 sts=4 et sw=4 tw=99:
#
# Compiles all entries.csv and meet.csv files into the final files.
#

from oplcsv import Csv
from usernames import get_username
import os
import sys
import toml
from interpolate_ages import interpolate

MEETID = 0


def nextmeetid():
    global MEETID
    x = MEETID
    MEETID = MEETID + 1
    return x


LIFTERID = 1  # Due to default seed of LIFTERIDMAP below.


def nextlifterid():
    global LIFTERID
    x = LIFTERID
    LIFTERID = LIFTERID + 1
    return x


# Global map of (Name => LifterID) mappings.
LIFTERIDMAP = {
    'Sean Stangl': 0
}


def get_lifterid(name):
    global LIFTERIDMAP
    try:
        return LIFTERIDMAP[name]
    except KeyError:
        lifterid = nextlifterid()
        LIFTERIDMAP[name] = lifterid
        return lifterid


# Global map of (Name => CyrillicName) mappings.
CYRILLICNAMEMAP = {
    'Sean Stangl': 'Шон Стангл'
}


def add_cyrillic_name(latin, cyrillic):
    global CYRILLICNAMEMAP
    if cyrillic != "":
        CYRILLICNAMEMAP[latin] = cyrillic


TESTED_FEDERATIONS = [
    "AAPLF",
    "AAU",
    "ADAU",
    "ADFPA",
    "ADFPF",
    "AEP",
    "AfricanPF",
    "APU",
    "AsianPF",
    "AusDFPF",
    "BAWLA",
    "BDFPA",
    "BP",
    "BVDK",
    "CommonwealthPF",
    "CPU",
    "CSST",
    "DSF",
    "EPA",
    "EPF",
    "FALPO",
    "FEMEPO",
    "FESUPO",
    "FFForce",
    "FPR",
    "IBSA",
    "IDFPA",
    "IDFPF",
    "IPF",
    "IrishPF",
    "JPA",
    "KRAFT",
    "LPF",
    "NAPF",
    "NASA",
    "NIPF",
    "NordicPF",
    "NSF",
    "NZPF",
    "OceaniaPF",
    "ParaPL",
    "PA",
    "PLZS",
    "PZKFiTS",
    "RAW",
    "RAW-CAN",
    "ScottishPL",
    "SSF",
    "SVNL",
    "THSPA",
    "USAPL",
    "WABDL",
    "WDFPF",
    "WelshPA",
    "WNPF"
]


# Reads in the map Name => Birthday (as date string).
def make_birthdays_map(lifterdir):
    csv = Csv(lifterdir + os.sep + 'birthdays.csv')

    nameidx = csv.index('Name')
    birthdayidx = csv.index('Birthday')

    birthdays = dict()
    for row in csv.rows:
        birthdays[row[nameidx]] = row[birthdayidx]

    return birthdays


# Fills in the Age column from the BirthYear column if possible.
# Inexact ages derived in this way are noted as '.5', for example '23.5',
# designating "either 23 or 24".
def age_from_birthyear(csv, date):
    if 'BirthYear' not in csv.fieldnames:
        return

    if 'Age' not in csv.fieldnames:
        csv.append_column('Age')

    birthyearidx = csv.index('BirthYear')
    ageidx = csv.index('Age')
    [year, month, day] = date.split('-')

    for row in csv.rows:
        if row[birthyearidx] and not row[ageidx]:
            lower_age = int(year) - int(row[birthyearidx]) - 1
            assert lower_age < 120
            assert lower_age > 3
            row[ageidx] = str(lower_age) + '.5'

# Fills in the Age column from the Birthday.


def age_from_birthday(csv, date, birthdays):
    if 'Age' not in csv.fieldnames:
        csv.append_column('Age')

    nameidx = csv.index('Name')
    ageidx = csv.index('Age')
    [year, month, day] = date.split('-')

    for row in csv.rows:
        name = row[nameidx]

        # Hardcoded ages take precedence.
        if row[ageidx] or name not in birthdays:
            continue

        [birthyear, birthmonth, birthday] = birthdays[name].split('-')
        assert birthyear < year

        years = int(year) - int(birthyear)
        if (int(month) < int(birthmonth) or
                (int(month) == int(birthmonth) and
                    int(day) <= int(birthday))):
            years -= 1

        row[ageidx] = str(years)


def agerange_from_division(csv, configtoml):
    if 'Division' in csv.fieldnames and configtoml:
        dividx = csv.index('Division')
        ageidx = csv.index('Age')
        ageclassidx = csv.index('AgeClass')

        divisions = configtoml["divisions"]

        # Match up the divisions to those specified in the config files
        for row in csv.rows:
            if row[ageidx] == '':
                for div_key in divisions:
                    div = divisions[div_key]
                    if row[dividx] == div["name"]:
                        row[ageclassidx] = str(
                            div["min"]) + "-" + str(div["max"])
                        break


def add_international_names(csv):
    if 'JapaneseName' in csv.fieldnames:
        intlidx = csv.index('JapaneseName')
        nameidx = csv.index('Name')
        for row in csv.rows:
            if row[nameidx] == '':
                row[nameidx] = row[intlidx]


def tested_from_division(division, federation):
    if federation == 'SPF':  # SPF Amateur doesn't test.
        return "No"

    if 'Amateur' in division:
        return "Yes"
    if 'AD' in division:  # "Amateur Division".
        return "Yes"
    if '_AAPF' in division:
        return "Yes"
    if '_ABPU' in division:
        return "Yes"
    if '_AWPC' in division:
        return "Yes"
    if federation == 'RPS' and 'Elite' in division:
        return "Yes"
    return "No"


# Appends to entriescsv and meetscsv, while assigning a MeetID mapping.
def addmeet(entriescsv, meetscsv, entriespath, meetpath, birthdays, configtoml):
    newentries = Csv(entriespath)
    newmeet = Csv(meetpath)

    # Remove some columns that are allowed as data but are ignored.
    newentries.remove_column_by_name("Country")
    newentries.remove_column_by_name("School")
    newentries.remove_column_by_name("Team")
    newentries.remove_column_by_name("State")
    newentries.remove_column_by_name("Country-State")
    newentries.remove_column_by_name("College/University")

    # Make use of Cyrillic names.
    if "CyrillicName" in newentries.fieldnames:
        nameidx = newentries.index('Name')
        cyridx = newentries.index('CyrillicName')
        for row in newentries.rows:
            add_cyrillic_name(row[nameidx], row[cyridx])
    newentries.remove_column_by_name("CyrillicName")

    # Make use of Japanese Names
    add_international_names(newentries)
    newentries.remove_column_by_name("JapaneseName")

    # Assign default Tested values.
    if 'Tested' not in newentries.fieldnames:
        newentries.append_column('Tested')
    testedidx = newentries.index('Tested')
    fed = newmeet.rows[0][newmeet.index('Federation')]
    for row in newentries.rows:
        if not row[testedidx]:
            if fed in TESTED_FEDERATIONS:
                row[testedidx] = "Yes"
            elif "Division" in newentries.fieldnames:
                row[testedidx] = \
                    tested_from_division(
                        row[newentries.index("Division")], fed)
            else:
                row[testedidx] = "No"

    # If the weight class column is provided but the bodyweight is not,
    # set the bodyweight equal to the class maximum, except for SHW.
    if 'WeightClassKg' not in newentries.fieldnames:
        newentries.append_column('WeightClassKg')
    if 'BodyweightKg' not in newentries.fieldnames:
        newentries.append_column('BodyweightKg')
    for row in newentries.rows:
        if not row[newentries.index('BodyweightKg')]:
            w = row[newentries.index('WeightClassKg')]
            if w and '+' not in w:
                row[newentries.index('BodyweightKg')] = w

    # Add the MeetID.
    assert "MeetID" in entriescsv.fieldnames
    assert "MeetID" in meetscsv.fieldnames
    assert "MeetID" not in newentries.fieldnames
    assert "MeetID" not in newmeet.fieldnames

    meetid = str(nextmeetid())

    newentries.append_column('MeetID')
    idx = newentries.index('MeetID')
    for row in newentries.rows:
        row[idx] = meetid

    newmeet.append_column('MeetID')
    idx = newmeet.index('MeetID')
    for row in newmeet.rows:
        row[idx] = meetid

    # Derive the path (e.g., "uspa/0039").
    # Input looks like "meet-path/uspa/0039/meet.csv".
    assert "MeetPath" not in newmeet.fieldnames
    path = meetpath[meetpath.index(
        os.sep) + 1: meetpath.rindex(os.sep)].replace(os.sep, '/')
    assert ',' not in path

    newmeet.append_column("MeetPath")
    idx = newmeet.index("MeetPath")
    for row in newmeet.rows:
        row[idx] = path

    # Add the LifterIDs.
    newentries.append_column('LifterID')
    idx = newentries.index('LifterID')
    nameidx = newentries.index('Name')
    for row in newentries.rows:
        row[idx] = str(get_lifterid(row[nameidx]))

    date = newmeet.rows[0][newmeet.index('Date')]

    # Try deriving from Birthday first.
    age_from_birthday(newentries, date, birthdays)

    # Otherwise, try deriving from BirthYear.
    age_from_birthyear(newentries, date)

    newentries.append_column('AgeClass')
    agerange_from_division(newentries, configtoml)

    # The Name column is used above to create the LifterID,
    # but it should not be written into the entries.csv.
    newentries.remove_column_by_name("Name")

    entriescsv.cat(newentries)
    meetscsv.cat(newmeet)


# Generates the lifters.csv from global state.
def build_lifterscsv(lifterdir, builddir):
    # The map of Name => LifterID has already been populated.
    global LIFTERIDMAP
    assert len(LIFTERIDMAP)

    # The map of Name => CyrillicName has already been populated.
    global CYRILLICNAMEMAP
    assert len(CYRILLICNAMEMAP)

    # Order by LifterID.
    ordered = sorted(LIFTERIDMAP.items(), key=lambda x: x[1])

    # Make a map of (Name => Instagram).
    instagramcsv = Csv(lifterdir + os.sep + 'social-instagram.csv')
    nameidx = instagramcsv.index('Name')
    igidx = instagramcsv.index('Instagram')
    instagram_map = dict()
    for row in instagramcsv.rows:
        instagram_map[row[nameidx]] = row[igidx]
    instagramcsv = None

    # Make a map of (Name => VKontakte).
    vkcsv = Csv(lifterdir + os.sep + 'social-vkontakte.csv')
    nameidx = vkcsv.index('Name')
    vkidx = vkcsv.index('Userpage')
    vk_map = dict()
    for row in vkcsv.rows:
        vk_map[row[nameidx]] = row[vkidx]
    vkcsv = None

    # Make a map of (Name => Color).
    colorcsv = Csv(lifterdir + os.sep + 'donator-colors.csv')
    nameidx = colorcsv.index('Name')
    coloridx = colorcsv.index('Color')
    colormap = dict()
    for row in colorcsv.rows:
        colormap[row[nameidx]] = row[coloridx]
    colorcsv = None

    lifterscsv = Csv()
    lifterscsv.append_column('LifterID')
    lifterscsv.append_column('Name')
    lifterscsv.append_column('CyrillicName')
    lifterscsv.append_column('Username')
    lifterscsv.append_column('Instagram')
    lifterscsv.append_column('VKontakte')
    lifterscsv.append_column('Color')

    for (name, lifterid) in ordered:
        instagram = ''
        if name in instagram_map:
            instagram = instagram_map[name]

        cyrname = ''
        if name in CYRILLICNAMEMAP:
            cyrname = CYRILLICNAMEMAP[name]

        vk = ''
        if name in vk_map:
            vk = vk_map[name]

        color = ''
        if name in colormap:
            color = colormap[name]

        username = get_username(name)

        row = [str(lifterid), name, cyrname, username, instagram, vk, color]
        lifterscsv.rows.append(row)

    lifterscsvpath = builddir + os.sep + 'lifters.csv'
    lifterscsv.write_filename(lifterscsvpath)


def main(builddir, meetdir, lifterdir):
    entriescsv = Csv()
    meetscsv = Csv()

    # Standardize the column order by hardcoding it here.
    # This is necessary for SQL import statements to work.
    # If this list is modified, also modify scripts/compile-sqlite.
    entriescsv.append_column('MeetID')
    entriescsv.append_column('LifterID')
    entriescsv.append_column('Sex')
    entriescsv.append_column('Event')
    entriescsv.append_column('Equipment')
    entriescsv.append_column('Age')
    entriescsv.append_column('Division')
    entriescsv.append_column('BodyweightKg')
    entriescsv.append_column('WeightClassKg')
    entriescsv.append_column('Squat1Kg')
    entriescsv.append_column('Squat2Kg')
    entriescsv.append_column('Squat3Kg')
    entriescsv.append_column('Squat4Kg')
    entriescsv.append_column('Best3SquatKg')
    entriescsv.append_column('Bench1Kg')
    entriescsv.append_column('Bench2Kg')
    entriescsv.append_column('Bench3Kg')
    entriescsv.append_column('Bench4Kg')
    entriescsv.append_column('Best3BenchKg')
    entriescsv.append_column('Deadlift1Kg')
    entriescsv.append_column('Deadlift2Kg')
    entriescsv.append_column('Deadlift3Kg')
    entriescsv.append_column('Deadlift4Kg')
    entriescsv.append_column('Best3DeadliftKg')
    entriescsv.append_column('TotalKg')
    entriescsv.append_column('Place')
    entriescsv.append_column('Wilks')
    entriescsv.append_column('McCulloch')
    entriescsv.append_column('Tested')
    entriescsv.append_column('AgeClass')

    # We remove these columns later, interpolate_ages needs to use them temporarily
    entriescsv.append_column('BirthDay')
    entriescsv.append_column('BirthYear')
    initial_entriescsv_num_columns = len(entriescsv.fieldnames) - 2

    meetscsv.append_column('MeetID')
    meetscsv.append_column('MeetPath')
    meetscsv.append_column('Federation')
    meetscsv.append_column('Date')
    meetscsv.append_column('MeetCountry')
    meetscsv.append_column('MeetState')
    meetscsv.append_column('MeetTown')
    meetscsv.append_column('MeetName')
    initial_meetscsv_num_columns = len(meetscsv.fieldnames)

    birthdays = make_birthdays_map(lifterdir)

    configpath = ''
    configtoml = None
    configfile = None
    for dirname, subdirs, files in os.walk(meetdir):
        # Modifying `subdirs` in-place will cause the next iteration
        # of the os.walk() generator to operate over the sorted list.
        subdirs.sort()

        if configpath and os.path.dirname(configpath) not in dirname:
            configpath = ''
            configfile.close()
            configtoml = None
            configfile = None

        if 'CONFIG.toml' in files:
            configpath = dirname + os.sep + 'CONFIG.toml'
            configfile = open(configpath, 'r', encoding='utf-8')
            configtoml = toml.load(configfile)

        if 'entries.csv' in files:
            assert 'meet.csv' in files
            entriespath = dirname + os.sep + 'entries.csv'
            meetpath = dirname + os.sep + 'meet.csv'
            addmeet(entriescsv, meetscsv, entriespath,
                    meetpath, birthdays, configtoml)

    entriescsv = interpolate(entriescsv, meetscsv)

    entriescsv.remove_column_by_name('BirthYear')
    entriescsv.remove_column_by_name('BirthDay')

    # Construct the lifters.csv.
    build_lifterscsv(lifterdir, builddir)

    entriescsvpath = builddir + os.sep + 'entries.csv'
    meetscsvpath = builddir + os.sep + 'meets.csv'

    entriescsv.write_filename(entriescsvpath)
    meetscsv.write_filename(meetscsvpath)

    # If these asserts fail, then new columns have been added.
    # Check the written files: new columns are at the end.
    # Columns need to be explicitly added above to be in a known order,
    # and then scripts/compile-sqlite needs to be notified of the column type.
    assert len(entriescsv.fieldnames) == initial_entriescsv_num_columns
    assert len(meetscsv.fieldnames) == initial_meetscsv_num_columns


if __name__ == '__main__':
    if len(sys.argv) != 4:
        print(' Usage: %s builddir meetdir lifterdir' %
              sys.argv[0], file=sys.stderr)
        sys.exit(1)
    main(sys.argv[1], sys.argv[2], sys.argv[3])
