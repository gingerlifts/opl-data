#!/usr/bin/env python3
# vim: set ts=8 sts=4 et sw=4 tw=99:
#
# Import data from the SVNL website.

from bs4 import BeautifulSoup
import errno
from oplcsv import Csv
import os
import sys
import urllib.request
import re


def gethtml(url):
    with urllib.request.urlopen(url) as r:
        return r.read().decode('utf-8')


def error(msg):
    print(msg, file=sys.stderr)
    sys.exit(1)


# URL will be like "tulokset/sm-kilpailut/16-18032018-klassinen-voimanosto-sm-ylojarvi-ylor".
def getdirname(url):
    return url.split('/')[-1]


def getmeetinfo(soup):
    csv = Csv()
    csv.fieldnames = ['Federation', 'Date', 'MeetCountry',
                      'MeetState', 'MeetTown', 'MeetName']

    # Get the facts table.
    tbody = soup.find('tbody')
    if len(tbody) == 0:
        error("Couldn't find the results table.")

    trs = tbody.find_all('tr')

    name = trs[1].text

    # Get the place & date.
    place_date = trs[2].text

    [place,dotdate] = place_date.split(',')

    place=place.strip()


    # The date is formatted as dd.-dd.mm.yyyy.
    assert '.' in dotdate

    #Remove the second day
    dotdate = re.sub('\.-.*?(?=\.)','',dotdate)

    [day, month, year] = dotdate.split('.')
    date = '%s-%s-%s' % (year, month, day)


    fed = 'SVNL'
    country = 'Finland'
    state = ''

    row = [fed, date, country, state, place, name]
    for i, r in enumerate(row):
        row[i] = r.replace(',', ' ').replace('  ', ' ').strip()
    csv.rows = [row]
    return csv


def getresults(soup):
    csv = Csv()

    # Get the results table.
    tbody = soup.find('tbody')
    if len(tbody) == 0:
        error("Couldn't find the results table.")


    trs = tbody.find_all('tr')

    # Get column information.
    headers = [x.text for x in trs[5].find_all('td')]

    csv.fieldnames = []
    for h in headers:
        if h == 'Sij.':
            csv.fieldnames += ['Place']
        elif h == 'Sarja':
            csv.fieldnames += ['WeightClassKg']
        elif h == 'Paino':
            csv.fieldnames += ['BodyweightKg']
        elif h == 'Nimi':
            csv.fieldnames += ['Name']
        elif h == 'SV':
            csv.fieldnames += ['BirthYear']
        elif h == 'Seura':
            csv.fieldnames += ['Team']
        elif h == 'JK1':
            csv.fieldnames += ['Squat1Kg']
        elif h == 'JK2':
            csv.fieldnames += ['Squat2Kg']
        elif h == 'JK3':
            csv.fieldnames += ['Squat3Kg']
        elif h == 'JK tul':
            csv.fieldnames += ['BestSquatKg']
        elif h == 'PP1':
            csv.fieldnames += ['Bench1Kg']
        elif h == 'PP2':
            csv.fieldnames += ['Bench2Kg']
        elif h == 'PP3':
            csv.fieldnames += ['Bench3Kg']
        elif h == 'PP tul':
            csv.fieldnames += ['BestBenchKg']
        elif h == 'MN1':
            csv.fieldnames += ['Deadlift1Kg']
        elif h == 'MN2':
            csv.fieldnames += ['Deadlift2Kg']
        elif h == 'MN3':
            csv.fieldnames += ['Deadlift3Kg']
        elif h == 'MN tul':
            csv.fieldnames += ['BestDeadliftKg']        
        elif h == 'YT':
            csv.fieldnames += ['TotalKg']
        elif h == 'Wilks':
            csv.fieldnames += ['Wilks']
        elif h == 'J.pist.':
            csv.fieldnames += ['Points']
        else:
            error("Unknown column name: \"%s\"" % h)

    # These columns are added from the category rows.
    csv.fieldnames += ['Division', 'Sex']

    append_eqp = False
    # Classic meets and pre 2011 meets won't mark equipment, work it out contextually
    if 'Equipment' not in csv.fieldnames:
        csv.fieldnames += ['Equipment']
        append_eqp = True


    divstate = 'Open'
    sexstate = 'F'

    for tr in trs[6:]:
        row = [x.text for x in tr.find_all('td')]

        if ''.join(row[0]).strip() != '' and row[0] != 'Sij.': # Skip blank rows and additional headers

            # Records are after data
            if row[0] == 'EnnÃ¤tykset':
                break

            # Rows of length >1 are actual results, of length 1 are categories.
            if len(row) == 1:
                # Extract sex information.
                text = row[0].lower()
                if 'naiset' in text:
                    sexstate = 'F'
                    text = text.replace('naiset', '').strip()
                elif 'miehet' in text:
                    sexstate = 'M'
                    text = text.replace('miehet', '').strip()
                elif text[0] == 'n':
                    sexstate = 'F'
                    text = text[1:]                    
                elif text[0] == 'm':
                    sexstate = 'M'
                    text = text[1:]
                # Extract division information.
                if '14' in text:
                    divstate = text.replace('14', 'Youth')
                elif '18' in text:
                    divstate = text.replace('18', 'Sub-Juniors')
                elif '23' in text:
                    divstate = text.replace('23', 'Juniors')
                elif '40' in text:
                    divstate = text.replace('40', 'Masters 1')
                elif '50' in text:
                    divstate = text.replace('50', 'Masters 2')
                elif '60' in text:
                    divstate = text.replace('60', 'Masters 3')
                elif '70' in text:
                    divstate = text.replace('70', 'Masters 4')
                elif 'avoin' in text:
                    divstate = text.replace('avoin', 'Open')
                elif len(text) !=0:
                    error("Unknown state: \"%s\"" % row[0])

            else:

                # Accumulate the row, but we need to look at the class of each td
                # to figure out whether lifts were good or bad.
                row = []
                for td in tr.find_all('td'):
                    text = td.text
                    # Switch to dots for decimals
                    text=text.replace(',','.')
                    s = td.s
                    if s:  # Failed lift.
                        text = '-' + text
                    if text == '-----':  # Skipped lift.
                        text = ''
                    row.append(text.strip().replace('  ', ' ').replace(',', ' '))

                row = row + [divstate, sexstate]

                if append_eqp:
                    row = row +['']
                csv.rows += [row]

    return csv


# The equipment is marked as "*" for Raw, or nothing for Single-ply.
def fixequipment(csv, meetcsv):
    meet_name = meetcsv.rows[0][5]

    raw_meet = False

    if 'klassisen' in meet_name.lower():
        raw_meet = True

    eqidx = csv.index('Equipment')

    for row in csv.rows:
        if raw_meet:
            row[eqidx] = 'Raw'
        else:
            if 'x' in row[eqidx]:
                row[eqidx] = 'Raw'
            elif row[eqidx] == '':
                row[eqidx] = 'Single-ply'
            else:
                error("Unknown equipment: \"%s\"" % row[eqidx])

def markevent(csv):
    assert 'Event' not in csv.fieldnames
    csv.append_column('Event')

    evtidx = csv.index('Event')

    def getevtindices(csv, fieldl):
        indexlist = []
        for f in fieldl:
            try:
                indexlist.append(csv.index(f))
            except ValueError:
                pass
        return indexlist

    squatidxl = getevtindices(
        csv, ['Squat1Kg', 'Squat2Kg', 'Squat3Kg', 'BestSquatKg'])
    benchidxl = getevtindices(
        csv, ['Bench1Kg', 'Bench2Kg', 'Bench3Kg', 'BestBenchKg'])
    deadliftidxl = getevtindices(
        csv, ['Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg', 'BestDeadliftKg'])

    for row in csv.rows:
        evt = ''
        for i in squatidxl:
            if row[i] != '':
                evt = evt + 'S'
                break
        for i in benchidxl:
            if row[i] != '':
                evt = evt + 'B'
                break
        for i in deadliftidxl:
            if row[i] != '':
                evt = evt + 'D'
                break
        row[evtidx] = evt


def remove_empty_cols_ignore_fieldname(csv):
    def iscolempty(csv, i):
        for row in csv.rows:
            if row[i]:
                return False
        return True

    def getemptyidx(csv):
        for i, col in enumerate(csv.fieldnames):
            if iscolempty(csv, i):
                return i
        return -1

    while True:
        idx = getemptyidx(csv)
        if idx == -1:
            return
        csv.remove_column_by_index(idx)


def main(url):

    # Get the results page from the page linked in the lists
    results_url = url.replace('tulokset/kansalliset-kilpailut/','')
    results_url = results_url.replace('tulokset/arvokilpailut/','')
    results_url = results_url.replace('tulokset/sm-kilpailut/','')
    html = gethtml(results_url)

    soup = BeautifulSoup(html, 'html.parser')

    meetcsv = getmeetinfo(soup)
    dirname = getdirname(url)
    entriescsv = getresults(soup)
    if len(entriescsv.rows) == 0:
        error("No rows found!")

    fixequipment(entriescsv,meetcsv)

 
    remove_empty_cols_ignore_fieldname(entriescsv)

    # Wilks will be automatically calculated later.
    # Feds get it wrong all the time.
    if 'Wilks' in entriescsv.fieldnames:
        entriescsv.remove_column_by_name('Wilks')

    if 'Points' in entriescsv.fieldnames:
        entriescsv.remove_column_by_name('Points')

    # Figure out event information.
    markevent(entriescsv)

    try:
        os.makedirs(dirname)
    except OSError as exception:
        if exception.errno != errno.EEXIST:
            raise
        else:
            error("Directory '%s' already exists." % dirname)

    with open(dirname + os.sep + 'entries.csv', 'w') as fd:
        entriescsv.write(fd)
    with open(dirname + os.sep + 'meet.csv', 'w') as fd:
        meetcsv.write(fd)
    with open(dirname + os.sep + 'URL', 'w') as fd:
        fd.write(url + "\n")

    print("Imported into %s." % dirname)


if __name__ == '__main__':
    if len(sys.argv) != 2:
        print("Usage: %s url" % sys.argv[0])
    main(sys.argv[1])
